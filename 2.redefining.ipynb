{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a3a89843-f44a-4631-bb41-b926fe72d8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "# 오류 경고 무시하기\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50e5e13-17b4-4951-bf1f-9a4cbaf924a2",
   "metadata": {},
   "source": [
    "# 1. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "057b3f7f-b03c-498d-9981-cf1f144067c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 파일들이 저장된 디렉토리 경로\n",
    "directory_path = \"./cluster\"\n",
    "\n",
    "# 디렉토리 내의 모든 CSV 파일 경로 가져오기\n",
    "csv_files = glob.glob(f'{directory_path}/*.csv')\n",
    "\n",
    "dataframes_dict = {}\n",
    "\n",
    "for file in csv_files:\n",
    "    # 파일 이름에서 확장자를 제외한 부분을 키로 사용\n",
    "    key = file.split('/')[-1].split('\\\\')[-1].split('.')[0]\n",
    "    \n",
    "    # CSV 파일을 데이터프레임으로 불러와 딕셔너리에 저장\n",
    "    dataframes_dict[key] = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e255cf77-ac80-4bf2-8b8d-29be24133857",
   "metadata": {},
   "source": [
    "# 2. geoDataFrame으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "cd147363-9bb1-47bb-8237-afc284a8df35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_geodata(df):\n",
    "    import pandas as pd\n",
    "    import geopandas as gpd\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # prepare and read data\n",
    "    F1 = './영역/서울시 상권분석서비스(영역-상권).shp' \n",
    "    D1 = gpd.read_file(F1, encoding='utf-8', crs=\"EPSG:5181\")\n",
    "\n",
    "    geo_data = pd.merge(df[['자치구_코드_명','상권_코드_명','서비스_업종_코드_명','총_유동인구_수', '연령대_10_유동인구_수', '연령대_20_유동인구_수',\n",
    "                           '연령대_30_유동인구_수', '연령대_40_유동인구_수', '연령대_50_유동인구_수', '연령대_60_이상_유동인구_수',\n",
    "                           '총_상주인구_수', '연령대_10_상주인구_수', '연령대_20_상주인구_수', '연령대_30_상주인구_수',\n",
    "                           '연령대_40_상주인구_수', '연령대_50_상주인구_수', '연령대_60_이상_상주인구_수',\n",
    "                           '유사_업종_점포_수', '총_직장_인구_수', '연령대_10_직장_인구_수', '연령대_20_직장_인구_수',\n",
    "                           '연령대_30_직장_인구_수', '연령대_40_직장_인구_수', '연령대_50_직장_인구_수',\n",
    "                           '연령대_60_이상_직장_인구_수', '집객시설수', '교통시설수', '당월_매출_금액', '연령대_10_매출_금액',\n",
    "                           '연령대_20_매출_금액', '연령대_30_매출_금액', '연령대_40_매출_금액', '연령대_50_매출_금액',\n",
    "                           '연령대_60_이상_매출_금액','cluster']],D1,left_on='상권_코드_명',right_on='TRDAR_CD_N')\n",
    "    geo_data = geo_data[['자치구_코드_명','상권_코드_명','서비스_업종_코드_명','총_유동인구_수', '연령대_10_유동인구_수', '연령대_20_유동인구_수',\n",
    "                           '연령대_30_유동인구_수', '연령대_40_유동인구_수', '연령대_50_유동인구_수', '연령대_60_이상_유동인구_수',\n",
    "                           '총_상주인구_수', '연령대_10_상주인구_수', '연령대_20_상주인구_수', '연령대_30_상주인구_수',\n",
    "                           '연령대_40_상주인구_수', '연령대_50_상주인구_수', '연령대_60_이상_상주인구_수',\n",
    "                           '유사_업종_점포_수', '총_직장_인구_수', '연령대_10_직장_인구_수', '연령대_20_직장_인구_수',\n",
    "                           '연령대_30_직장_인구_수', '연령대_40_직장_인구_수', '연령대_50_직장_인구_수',\n",
    "                           '연령대_60_이상_직장_인구_수', '집객시설수', '교통시설수', '당월_매출_금액', '연령대_10_매출_금액',\n",
    "                           '연령대_20_매출_금액', '연령대_30_매출_금액', '연령대_40_매출_금액', '연령대_50_매출_금액',\n",
    "                           '연령대_60_이상_매출_금액','cluster','geometry']]\n",
    "    geo_data = gpd.GeoDataFrame(geo_data)\n",
    "\n",
    "    return geo_data\n",
    "\n",
    "def merge_polygon(geo_data,n):\n",
    "    import geopandas as gpd\n",
    "    from shapely.ops import unary_union\n",
    "    data = dict(자치구=[], 상권_코드=[], 서비스_업종_코드_명=[],총_유동인구_수=[], 연령대_10_유동인구_수=[], 연령대_20_유동인구_수=[],\n",
    "                           연령대_30_유동인구_수=[], 연령대_40_유동인구_수=[], 연령대_50_유동인구_수=[], 연령대_60_이상_유동인구_수=[],\n",
    "                            총_상주인구_수=[], 연령대_10_상주인구_수=[], 연령대_20_상주인구_수=[], 연령대_30_상주인구_수=[],\n",
    "                           연령대_40_상주인구_수=[], 연령대_50_상주인구_수=[], 연령대_60_이상_상주인구_수=[],유사_업종_점포_수=[],\n",
    "                            총_직장_인구_수=[], 연령대_10_직장_인구_수=[], 연령대_20_직장_인구_수=[], 연령대_30_직장_인구_수=[], \n",
    "                            연령대_40_직장_인구_수=[], 연령대_50_직장_인구_수=[], 연령대_60_이상_직장_인구_수= [] , 집객시설수=[], 교통시설수=[], \n",
    "                            당월_매출_금액=[], 연령대_10_매출_금액=[], 연령대_20_매출_금액=[], 연령대_30_매출_금액=[], 연령대_40_매출_금액=[], \n",
    "                            연령대_50_매출_금액=[], 연령대_60_이상_매출_금액=[], cluster=[],geometry=[])\n",
    "    df = gpd.GeoDataFrame(data)\n",
    "    # n = code\n",
    "    cluster = geo_data['cluster'][0]\n",
    "    service = geo_data['서비스_업종_코드_명'][0]\n",
    "    # geo_data['result']=None\n",
    "    while len(geo_data) != 0:\n",
    "        area_list = []\n",
    "        intersects_sum = 0\n",
    "        while intersects_sum != 1:\n",
    "            geo_data['result'] = None\n",
    "            for row in range(len(geo_data)):\n",
    "                if geo_data['geometry'][0].intersects(geo_data['geometry'][row]):\n",
    "                    geo_data['result'][row]=1\n",
    "                else :\n",
    "                    geo_data['result'][row]=0\n",
    "            intersects_sum = geo_data['result'].sum()\n",
    "            geo_data_union = geo_data[geo_data['result']==1]\n",
    "            mergedPolys = unary_union(geo_data_union['geometry'])\n",
    "            for value in geo_data_union['자치구_코드_명']:\n",
    "                area_list.append(value)\n",
    "            geo_data['result'][0] = 0\n",
    "            geo_data = geo_data[geo_data['result']==0]\n",
    "            geo_data.loc[0] = [geo_data_union['자치구_코드_명'][0],n,service,geo_data_union['총_유동인구_수'].sum(),geo_data_union['연령대_10_유동인구_수'].sum(),geo_data_union['연령대_20_유동인구_수'].sum(),geo_data_union['연령대_30_유동인구_수'].sum(),geo_data_union['연령대_40_유동인구_수'].sum(),geo_data_union['연령대_50_유동인구_수'].sum(),geo_data_union['연령대_60_이상_유동인구_수'].sum(),\n",
    "                                               geo_data_union['총_상주인구_수'].sum(),geo_data_union['연령대_10_상주인구_수'].sum(),geo_data_union['연령대_20_상주인구_수'].sum(),geo_data_union['연령대_30_상주인구_수'].sum(),geo_data_union['연령대_40_상주인구_수'].sum(),geo_data_union['연령대_50_상주인구_수'].sum(),geo_data_union['연령대_60_이상_상주인구_수'].sum(),\n",
    "                                               geo_data_union['유사_업종_점포_수'].sum(),geo_data_union['총_직장_인구_수'].sum(),geo_data_union['연령대_10_직장_인구_수'].sum(),geo_data_union['연령대_20_직장_인구_수'].sum(),geo_data_union['연령대_30_직장_인구_수'].sum(),geo_data_union['연령대_40_직장_인구_수'].sum(),geo_data_union['연령대_50_직장_인구_수'].sum(),geo_data_union['연령대_60_이상_직장_인구_수'].sum(),\n",
    "                                               geo_data_union['집객시설수'].sum(),geo_data_union['교통시설수'].sum(),geo_data_union['당월_매출_금액'].sum(),geo_data_union['연령대_10_매출_금액'].sum(),geo_data_union['연령대_20_매출_금액'].sum(),geo_data_union['연령대_30_매출_금액'].sum(),geo_data_union['연령대_40_매출_금액'].sum(),geo_data_union['연령대_50_매출_금액'].sum(),geo_data_union['연령대_60_이상_매출_금액'].sum(),cluster,mergedPolys,1]\n",
    "        area_list = list(set(area_list))\n",
    "        for idx in range(len(area_list)):\n",
    "            df.loc[len(df)] = [area_list[idx],n,service,geo_data['총_유동인구_수'][0],geo_data['연령대_10_유동인구_수'][0],geo_data['연령대_20_유동인구_수'][0],geo_data['연령대_30_유동인구_수'][0],geo_data['연령대_40_유동인구_수'][0],geo_data['연령대_50_유동인구_수'][0],geo_data['연령대_60_이상_유동인구_수'][0],\n",
    "                                                        geo_data['총_상주인구_수'][0],geo_data['연령대_10_상주인구_수'][0],geo_data['연령대_20_상주인구_수'][0],geo_data['연령대_30_상주인구_수'][0],geo_data['연령대_40_상주인구_수'][0],geo_data['연령대_50_상주인구_수'][0],geo_data['연령대_60_이상_상주인구_수'][0],\n",
    "                                                       geo_data['유사_업종_점포_수'][0],geo_data['총_직장_인구_수'][0],geo_data['연령대_10_직장_인구_수'][0],geo_data['연령대_20_직장_인구_수'][0],geo_data['연령대_30_직장_인구_수'][0],geo_data['연령대_40_직장_인구_수'][0],geo_data['연령대_50_직장_인구_수'][0],geo_data['연령대_60_이상_직장_인구_수'][0],\n",
    "                                                       geo_data['집객시설수'][0],geo_data['교통시설수'][0],geo_data['당월_매출_금액'][0],geo_data['연령대_10_매출_금액'][0],geo_data['연령대_20_매출_금액'][0],geo_data['연령대_30_매출_금액'][0],geo_data['연령대_40_매출_금액'][0],geo_data['연령대_50_매출_금액'][0],geo_data['연령대_60_이상_매출_금액'][0],\n",
    "                                                       cluster,geo_data['geometry'][0]]\n",
    "        geo_data = geo_data.drop(0, axis=0).reset_index(drop=True)\n",
    "        n+=1\n",
    "    return df\n",
    "\n",
    "def concat_geodata(merge_polygon_data):\n",
    "    for i in range(1,len(merge_polygon_data)):\n",
    "        if i == 1:\n",
    "            df = pd.concat([merge_polygon_data['df_0'],merge_polygon_data['df_1']],axis=0)\n",
    "        else:\n",
    "            df = pd.concat([df,merge_polygon_data[f'df_{i}']],axis=0)\n",
    "    df = df.drop_duplicates(subset = ['상권_코드', '서비스_업종_코드_명', 'cluster'], keep = 'first') \n",
    "    # list = []\n",
    "    # for i in range(1,len(df)+1):\n",
    "    #     list.append(i)\n",
    "    # df['상권_코드'] = list\n",
    "    df = df.reset_index(drop=True)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def evaluation_score(df,score1,score2,score3,score4,score5_1,score5_2,score5_3):\n",
    "    df[['집객력(점수)','매출액(점수)','경쟁업체(점수)','편의성(점수)','잠재고객(점수)']] = 0\n",
    "    \n",
    "    # 집객력\n",
    "    for i in range(len(df)):\n",
    "        if df['집객시설수'][i].sum()<=score1[0]:\n",
    "            df['집객력(점수)'][i] = 1\n",
    "        elif df['집객시설수'][i].sum()<=score1[1]:\n",
    "            df['집객력(점수)'][i] = 2\n",
    "        elif df['집객시설수'][i].sum()<=score1[2]:\n",
    "            df['집객력(점수)'][i] = 3\n",
    "        elif df['집객시설수'][i].sum()<=score1[3]:\n",
    "            df['집객력(점수)'][i] = 4\n",
    "        else:\n",
    "            df['집객력(점수)'][i] = 5\n",
    "\n",
    "                \n",
    "        # 매출액\n",
    "        if df['당월_매출_금액'][i].sum()<=score2[0]:\n",
    "            df['매출액(점수)'][i] = 1\n",
    "        elif df['당월_매출_금액'][i].sum()<=score2[1]:\n",
    "            df['매출액(점수)'][i] = 2\n",
    "        elif df['당월_매출_금액'][i].sum()<=score2[2]:\n",
    "            df['매출액(점수)'][i] = 3\n",
    "        elif df['당월_매출_금액'][i].sum()<=score2[3]:\n",
    "            df['매출액(점수)'][i] = 4\n",
    "        else:\n",
    "            df['매출액(점수)'][i] = 5\n",
    "    \n",
    "        # 경쟁업체\n",
    "        if df['유사_업종_점포_수'][i].sum()<=score3[0]:\n",
    "            df['경쟁업체(점수)'][i] = 1\n",
    "        elif df['유사_업종_점포_수'][i].sum()<=score3[1]:\n",
    "            df['경쟁업체(점수)'][i] = 2\n",
    "        elif df['유사_업종_점포_수'][i].sum()<=score3[2]:\n",
    "            df['경쟁업체(점수)'][i] = 3\n",
    "        elif df['유사_업종_점포_수'][i].sum()<=score3[3]:\n",
    "            df['경쟁업체(점수)'][i] = 4\n",
    "        else:\n",
    "            df['경쟁업체(점수)'][i] = 5\n",
    "    \n",
    "        # 편의성\n",
    "        if df['교통시설수'][i].sum()<=score4[0]:\n",
    "            df['편의성(점수)'][i] = 1\n",
    "        elif df['교통시설수'][i].sum()<=score4[1]:\n",
    "            df['편의성(점수)'][i] = 2\n",
    "        elif df['교통시설수'][i].sum()<=score4[2]:\n",
    "            df['편의성(점수)'][i] = 3\n",
    "        elif df['교통시설수'][i].sum()<=score4[3]:\n",
    "            df['편의성(점수)'][i] = 4\n",
    "        else:\n",
    "            df['편의성(점수)'][i] = 5\n",
    "    \n",
    "        # 잠재고객\n",
    "        ## 상주인구\n",
    "        if df['총_상주인구_수'][i].sum()<=score5_1[0]:\n",
    "            df['잠재고객(점수)'][i] += 1\n",
    "        elif df['총_상주인구_수'][i].sum()<=score5_1[1]:\n",
    "            df['잠재고객(점수)'][i] += 2\n",
    "        elif df['총_상주인구_수'][i].sum()<=score5_1[2]:\n",
    "            df['잠재고객(점수)'][i] += 3\n",
    "        elif df['총_상주인구_수'][i].sum()<=score5_1[3]:\n",
    "            df['잠재고객(점수)'][i] += 4\n",
    "        else:\n",
    "            df['잠재고객(점수)'][i] += 5\n",
    "        \n",
    "        ## 유동인구\n",
    "        if df['총_유동인구_수'][i].sum()<=score5_2[0]:\n",
    "            df['잠재고객(점수)'][i] += 1\n",
    "        elif df['총_유동인구_수'][i].sum()<=score5_2[1]:\n",
    "            df['잠재고객(점수)'][i] += 2\n",
    "        elif df['총_유동인구_수'][i].sum()<=score5_2[2]:\n",
    "            df['잠재고객(점수)'][i] += 3\n",
    "        elif df['총_유동인구_수'][i].sum()<=score5_2[3]:\n",
    "            df['잠재고객(점수)'][i] += 4\n",
    "        else:\n",
    "            df['잠재고객(점수)'][i] += 5\n",
    "        \n",
    "        ## 직장인구\n",
    "        if df['총_직장_인구_수'][i].sum()<=score5_3[0]:\n",
    "            df['잠재고객(점수)'][i] += 1\n",
    "        elif df['총_직장_인구_수'][i].sum()<=score5_3[1]:\n",
    "            df['잠재고객(점수)'][i] += 2\n",
    "        elif df['총_직장_인구_수'][i].sum()<=score5_3[2]:\n",
    "            df['잠재고객(점수)'][i] += 3\n",
    "        elif df['총_직장_인구_수'][i].sum()<=score5_3[3]:\n",
    "            df['잠재고객(점수)'][i] += 4\n",
    "        else:\n",
    "            df['잠재고객(점수)'][i] += 5\n",
    "\n",
    "    df['잠재고객(점수)'] = df['잠재고객(점수)'] / 3\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "86717310-063d-4103-9bec-cf4e3f127562",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "7",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2606\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2630\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 7",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[158], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m merge_polygon_data \u001b[38;5;241m=\u001b[39m {}  \u001b[38;5;66;03m# Dictionary to store DataFrames\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(cluster_data)):\n\u001b[1;32m---> 22\u001b[0m     merge_polygon_data[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mmerge_polygon\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcluster_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgeo_data_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     num \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m  merge_polygon_data[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m상권_코드\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m-\u001b[39m merge_polygon_data[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m상권_코드\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     25\u001b[0m df_all \u001b[38;5;241m=\u001b[39m concat_geodata(merge_polygon_data)\n",
      "Cell \u001b[1;32mIn[157], line 54\u001b[0m, in \u001b[0;36mmerge_polygon\u001b[1;34m(geo_data, n)\u001b[0m\n\u001b[0;32m     52\u001b[0m geo_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(geo_data)):\n\u001b[1;32m---> 54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m geo_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mintersects(\u001b[43mgeo_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgeometry\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m]\u001b[49m):\n\u001b[0;32m     55\u001b[0m         geo_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m][row]\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m :\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\geopandas\\geoseries.py:635\u001b[0m, in \u001b[0;36mGeoSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m--> 635\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapped_pandas_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m__getitem__\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\geopandas\\geoseries.py:628\u001b[0m, in \u001b[0;36mGeoSeries._wrapped_pandas_method\u001b[1;34m(self, mtd, *args, **kwargs)\u001b[0m\n\u001b[0;32m    626\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapped_pandas_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, mtd, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    627\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Wrap a generic pandas method to ensure it returns a GeoSeries\"\"\"\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmtd\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(val) \u001b[38;5;241m==\u001b[39m Series:\n\u001b[0;32m    630\u001b[0m         val\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;241m=\u001b[39m GeoSeries\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:1007\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1004\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1007\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m   1010\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1012\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:1116\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1116\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 7"
     ]
    }
   ],
   "source": [
    "geo_df_dict = {}\n",
    "num  = 1\n",
    "for key, value in dataframes_dict.items():\n",
    "    geo_data = create_geodata(value)\n",
    "\n",
    "    # Assuming 'your_column' is the column you're working with\n",
    "    if isinstance(geo_data['geometry'], gpd.geoseries.GeoSeries):\n",
    "        geo_data['geometry'] = geo_data['geometry'].buffer(5)\n",
    "        geo_data['result'] = None\n",
    "        \n",
    "        cluster_data = {}  # Dictionary to store DataFrames\n",
    "    \n",
    "        for i in range(geo_data['cluster'].nunique()):\n",
    "            cluster_data[f'geo_data_{i}'] = geo_data[geo_data['cluster'] == i].reset_index(drop=True)\n",
    "    \n",
    "    else:\n",
    "        print(\"It's not a GeoSeries.\")\n",
    "\n",
    "    merge_polygon_data = {}  # Dictionary to store DataFrames\n",
    "    \n",
    "    for i in range(len(cluster_data)):\n",
    "        merge_polygon_data[f'df_{i}'] = merge_polygon(cluster_data[f'geo_data_{i}'],num)\n",
    "        num +=  merge_polygon_data[f'df_{i}']['상권_코드'].max() - merge_polygon_data[f'df_{i}']['상권_코드'].min() + 1\n",
    "\n",
    "    df_all = concat_geodata(merge_polygon_data)\n",
    "\n",
    "    score1 = [np.percentile(df_all['집객시설수'], q) for q in [20, 40, 60, 80]]\n",
    "    score2 = [np.percentile(df_all['당월_매출_금액'], q) for q in [20, 40, 60, 80]]\n",
    "    score3 = [np.percentile(df_all['유사_업종_점포_수'], q) for q in [20, 40, 60, 80]]\n",
    "    score4 = [np.percentile(df_all['교통시설수'], q) for q in [20, 40, 60, 80]]\n",
    "    score5_1 = [np.percentile(df_all['총_상주인구_수'], q) for q in [20, 40, 60, 80]]\n",
    "    score5_2 = [np.percentile(df_all['총_유동인구_수'], q) for q in [20, 40, 60, 80]]\n",
    "    score5_3 = [np.percentile(df_all['총_직장_인구_수'], q) for q in [20, 40, 60, 80]]\n",
    "\n",
    "    df_final = evaluation_score(df_all,score1,score2,score3,score4,score5_1,score5_2,score5_3)\n",
    "    geo_df_dict[key] = df_final\n",
    "\n",
    "redefined_df = pd.concat(geo_df_dict.values(), ignore_index = True)\n",
    "\n",
    "redefined_df.crs = \"EPSG:5181\"\n",
    "redefined_df = redefined_df.to_crs(epsg = 4326)\n",
    "\n",
    "redefined_df.to_csv(\"./final/redefined_df.csv\", index = False)\n",
    "\n",
    "redefined_df = pd.read_csv(\"./final/redefined_df.csv\")\n",
    "\n",
    "import shapely.wkt\n",
    "redefined_df['geometry'] = redefined_df['geometry'].apply(lambda x: shapely.wkt.loads(x))\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import LineString, MultiLineString\n",
    "\n",
    "# Assuming your DataFrame is called df and the geometry column is called 'geometry'\n",
    "# Replace 'geometry' with the actual column name if it's different\n",
    "\n",
    "redefined_df['geometry2'] = None\n",
    "\n",
    "for i in range(len(redefined_df)):\n",
    "    if redefined_df['geometry'][i].geom_type == 'Polygon':\n",
    "        redefined_df['geometry2'][i] = LineString(redefined_df['geometry'][i].exterior)\n",
    "    elif redefined_df['geometry'][i].geom_type == 'MultiPolygon':\n",
    "        redefined_df['geometry2'][i] = MultiLineString([LineString(poly.exterior) for poly in redefined_df['geometry'][i].geoms])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a360e9-6fc2-4ff9-a4d6-3a036bdff21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "melt_df_1 = redefined_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3561f8-42a9-4a07-abcd-e84136f2a0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "redefined_df_1 = redefined_df[['자치구', '상권_코드', '서비스_업종_코드_명', '총_유동인구_수', '총_상주인구_수', '총_직장_인구_수', \n",
    "                             '유사_업종_점포_수', '집객시설수', '교통시설수', '당월_매출_금액', 'cluster', 'geometry', \n",
    "                             '집객력(점수)', '매출액(점수)', '경쟁업체(점수)', '편의성(점수)', '잠재고객(점수)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d83da95-1f3d-4be2-a732-6e33b5e0d1c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1006):\n",
    "    if (redefined_df_1[redefined_df_1['상권_코드'] == i]['서비스_업종_코드_명'].value_counts() > 2).any():\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848e97ad-39ab-4aed-a228-0ca933091e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "redefined_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b3847f-8d98-4981-8bd8-4b9c77c1a2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "melt_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a7f940-c643-4938-bcaf-7c4a85447081",
   "metadata": {},
   "outputs": [],
   "source": [
    "redefined_df_1.to_csv(\"./final/redefined_df_1.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6831060-c245-4035-a4c8-56e3b80b5a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "melt_df_1.to_csv(\"./final/melt_1.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4523964e-491b-45a4-8050-c2bb80782447",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
